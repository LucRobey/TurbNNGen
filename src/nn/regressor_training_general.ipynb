{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac02d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from datetime import datetime\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from src.nn.regression_dataset import RegressionDataset\n",
    "from src.nn.to_tensor import ToTensor\n",
    "from src.nn.create_data_loaders import create_data_loaders\n",
    "from src.nn.cnn_regressor import CNNRegressor\n",
    "from src.nn.training import training\n",
    "from src.nn.plot_losses import plot_losses\n",
    "from src.nn.weighted_mse_loss import WeightedMSELoss\n",
    "import src.ctes.num_ctes as nctes\n",
    "import src.ctes.path_ctes as pctes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac3ab8e-2569-4849-be1c-e9643228d0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An epoch takes around 3 minutes (train + val) on a school computer with GPUs\n",
    "# Call several times the following function to start several trainings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db9cd1f2-7f23-493c-bec2-62bba8e17d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_general(data_path, batch_size, valid_size, test_size, criterion, model_name, n_epochs, dropout_probs = None, lr = 0.001, weight_decay = 0):\n",
    "    seed = 42\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    data_path = data_path \n",
    "    transform = ToTensor()\n",
    "    sample_size = nctes.LEN_SAMPLE\n",
    "\n",
    "    print(\"Getting data path...\")\n",
    "    data = RegressionDataset(data_path, transform, sample_size)\n",
    "    batch_size = batch_size\n",
    "    valid_size = valid_size\n",
    "    test_size = test_size\n",
    "    print(\"Data path saved.\")\n",
    "    print(\"\")\n",
    "    \n",
    "    print(\"Checking GPU availability...\")\n",
    "    train_loader, valid_loader, test_loader = create_data_loaders(batch_size, valid_size, test_size, data)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('Using device ' + str(device))\n",
    "    print(\"\")\n",
    "    sample_size = nctes.LEN_SAMPLE\n",
    "\n",
    "    # model params \n",
    "    dropout_probs = dropout_probs\n",
    "    model = CNNRegressor(input_size=sample_size, dropout_probs=dropout_probs)\n",
    "    model.to(device=device)\n",
    "    criterion = criterion\n",
    "    model_name = model_name\n",
    "    params = model.parameters()\n",
    "    lr = lr\n",
    "    weight_decay = weight_decay\n",
    "    n_epochs = n_epochs\n",
    "\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params, lr, weight_decay = weight_decay)\n",
    "\n",
    "    print(\"Saving model parameters...\")\n",
    "    timestamp = datetime.now().strftime('%Y_%m_%d__%H_%M_%S')\n",
    "    hyperparams_path = f\"../../data/hyperparams_{timestamp}.npz\"\n",
    "    model_path = f\"../../data/model_{timestamp}.pt\"\n",
    "    losses_path = f\"../../data/losses_{timestamp}.npz\"\n",
    "    np.savez(hyperparams_path, \n",
    "             len=len(data), \n",
    "             test_size=test_size, \n",
    "             valid_size=valid_size, \n",
    "             epochs=n_epochs, \n",
    "             batch_size=batch_size, \n",
    "             criterion=str(criterion), \n",
    "             optimizer=str(optimizer), \n",
    "             lr=lr,\n",
    "             seed=seed,\n",
    "             weight_decay = weight_decay,\n",
    "             dropout_probs = dropout_probs, \n",
    "             model_name = model_name)\n",
    "    print(\"Model saved.\")\n",
    "    print(\"\")\n",
    "    \n",
    "    train_losses, valid_losses = training(n_epochs, train_loader, valid_loader, model, criterion, optimizer, device, model_path)\n",
    "\n",
    "    print(\"Saving losses...\")\n",
    "    np.savez(losses_path , train=np.array(train_losses), val=np.array(valid_losses))\n",
    "    print(\"Losses saved.\")\n",
    "\n",
    "    return train_losses, valid_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ba6a91-03e4-4457-90fe-f80394d14bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data path...\n",
      "Data path saved.\n",
      "\n",
      "Checking GPU availability...\n",
      "Using device cuda\n",
      "\n",
      "Saving model parameters...\n",
      "Model saved.\n",
      "\n",
      "Epoch 1/2 ...\n",
      "Training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1366/1366 [02:37<00:00,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 342/342 [00:13<00:00, 26.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \ttraining Loss: 0.191912 \tvalidation Loss: 0.131715\n",
      "Validation loss decreased (inf --> 0.131715).  Saving model ...\n",
      "Epoch 2/2 ...\n",
      "Training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████████▏    | 1288/1366 [02:34<00:09,  8.36it/s]"
     ]
    }
   ],
   "source": [
    "data_path = pctes.DATAPATH_fm\n",
    "batch_size = 6\n",
    "valid_size = 0.2\n",
    "test_size = 0.2\n",
    "criterion = nn.MSELoss()\n",
    "dropout_probs=[0.7, 0.7, 0.7, 0.7, 0.6, 0.6, 0.5, 0.5, 0.5, 0.5, 0.6, 0.6, 0.7, 0.7]\n",
    "model_name = \"Variable dropout probas and L2 regularization\" # name given to the trained model\n",
    "lr = 0.001\n",
    "weight_decay = 1e-5 # for L2 regularization\n",
    "n_epochs = 2\n",
    "\n",
    "train_losses, valid_losses,  = training_general(data_path, batch_size, valid_size, test_size, criterion, model_name, n_epochs, dropout_probs, lr, weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc2a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(len(train_losses), [train_losses, valid_losses], [\"Train\", \"Val\"])"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
